{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7127017",
   "metadata": {},
   "source": [
    "# Linear Regression Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f6fb43",
   "metadata": {},
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad0c080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20237cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     TV  Radio  Newspaper  Sales\n",
       "0             1  230.1   37.8       69.2   22.1\n",
       "1             2   44.5   39.3       45.1   10.4\n",
       "2             3   17.2   45.9       69.3    9.3\n",
       "3             4  151.5   41.3       58.5   18.5\n",
       "4             5  180.8   10.8       58.4   12.9\n",
       "..          ...    ...    ...        ...    ...\n",
       "195         196   38.2    3.7       13.8    7.6\n",
       "196         197   94.2    4.9        8.1    9.7\n",
       "197         198  177.0    9.3        6.4   12.8\n",
       "198         199  283.6   42.0       66.2   25.5\n",
       "199         200  232.1    8.6        8.7   13.4\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sales.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5cafb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare X (features) and y (target)\n",
    "feature_cols = ['TV', 'Newspaper', 'Radio']\n",
    "X = df[feature_cols]\n",
    "y = df['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "220ea360",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# do train_test_split (train:75, test:25)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# do scaling for training convergence\n",
    "X_train, X_test = scaler.fit_transform(X_train), scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23da03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine whether system supports CUDA or not \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2ef8f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert numpy arrays into pytorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd6fde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = []\n",
    "\n",
    "class LinearRegression(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features):\n",
    "        super(LinearRegression, self).__init__()       \n",
    "        self.num_features = num_features\n",
    "        self.linear = torch.nn.Linear(num_features, 1)\n",
    "        self.linear.weight.detach().normal_(0, .1)\n",
    "        self.linear.bias.detach().zero_()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        yhat = logits.view(-1)\n",
    "        return yhat\n",
    "    \n",
    "\n",
    "    def train(self, x, y, num_epochs, learning_rate=0.1):\n",
    "        \n",
    "        # use gradient descent as the optimizer\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=learning_rate)\n",
    "        \n",
    "        for e in range(num_epochs):\n",
    "            \n",
    "            # compute outputs ###\n",
    "            yhat = self.forward(x)\n",
    "            \n",
    "            # compute the loss\n",
    "            loss = F.mse_loss(yhat, y, reduction='mean')\n",
    "            \n",
    "            # reset gradients from the previous interaction\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # comp. gradients\n",
    "            loss.backward()          \n",
    "            \n",
    "            # update weights and bias\n",
    "            optimizer.step()\n",
    "\n",
    "            \n",
    "            ### Logging ####\n",
    "            with torch.no_grad():\n",
    "                yhat = self.forward(x)\n",
    "                curr_loss = F.mse_loss(yhat, y, reduction='mean')\n",
    "                print('Epoch: %03d' %(e+1), end='')\n",
    "                print(' | MSE: %.3f' %curr_loss)\n",
    "                cost.append(curr_loss) \n",
    "            \n",
    "    def predict(self, x):\n",
    "        predictions = self.forward(x)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "577e81d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 | MSE: 140.472\n",
      "Epoch: 002 | MSE: 90.601\n",
      "Epoch: 003 | MSE: 58.955\n",
      "Epoch: 004 | MSE: 38.825\n",
      "Epoch: 005 | MSE: 25.991\n",
      "Epoch: 006 | MSE: 17.794\n",
      "Epoch: 007 | MSE: 12.549\n",
      "Epoch: 008 | MSE: 9.187\n",
      "Epoch: 009 | MSE: 7.029\n",
      "Epoch: 010 | MSE: 5.641\n",
      "Epoch: 011 | MSE: 4.746\n",
      "Epoch: 012 | MSE: 4.168\n",
      "Epoch: 013 | MSE: 3.795\n",
      "Epoch: 014 | MSE: 3.552\n",
      "Epoch: 015 | MSE: 3.394\n",
      "Epoch: 016 | MSE: 3.291\n",
      "Epoch: 017 | MSE: 3.223\n",
      "Epoch: 018 | MSE: 3.179\n",
      "Epoch: 019 | MSE: 3.149\n",
      "Epoch: 020 | MSE: 3.130\n",
      "Epoch: 021 | MSE: 3.116\n",
      "Epoch: 022 | MSE: 3.107\n",
      "Epoch: 023 | MSE: 3.101\n",
      "Epoch: 024 | MSE: 3.097\n",
      "Epoch: 025 | MSE: 3.094\n",
      "Epoch: 026 | MSE: 3.092\n",
      "Epoch: 027 | MSE: 3.091\n",
      "Epoch: 028 | MSE: 3.090\n",
      "Epoch: 029 | MSE: 3.089\n",
      "Epoch: 030 | MSE: 3.088\n",
      "Epoch: 031 | MSE: 3.088\n",
      "Epoch: 032 | MSE: 3.088\n",
      "Epoch: 033 | MSE: 3.087\n",
      "Epoch: 034 | MSE: 3.087\n",
      "Epoch: 035 | MSE: 3.087\n",
      "Epoch: 036 | MSE: 3.087\n",
      "Epoch: 037 | MSE: 3.087\n",
      "Epoch: 038 | MSE: 3.087\n",
      "Epoch: 039 | MSE: 3.087\n",
      "Epoch: 040 | MSE: 3.087\n",
      "Epoch: 041 | MSE: 3.087\n",
      "Epoch: 042 | MSE: 3.087\n",
      "Epoch: 043 | MSE: 3.087\n",
      "Epoch: 044 | MSE: 3.087\n",
      "Epoch: 045 | MSE: 3.087\n",
      "Epoch: 046 | MSE: 3.087\n",
      "Epoch: 047 | MSE: 3.087\n",
      "Epoch: 048 | MSE: 3.087\n",
      "Epoch: 049 | MSE: 3.087\n",
      "Epoch: 050 | MSE: 3.087\n",
      "Epoch: 051 | MSE: 3.087\n",
      "Epoch: 052 | MSE: 3.087\n",
      "Epoch: 053 | MSE: 3.087\n",
      "Epoch: 054 | MSE: 3.087\n",
      "Epoch: 055 | MSE: 3.087\n",
      "Epoch: 056 | MSE: 3.087\n",
      "Epoch: 057 | MSE: 3.087\n",
      "Epoch: 058 | MSE: 3.087\n",
      "Epoch: 059 | MSE: 3.087\n",
      "Epoch: 060 | MSE: 3.087\n",
      "Epoch: 061 | MSE: 3.087\n",
      "Epoch: 062 | MSE: 3.087\n",
      "Epoch: 063 | MSE: 3.087\n",
      "Epoch: 064 | MSE: 3.087\n",
      "Epoch: 065 | MSE: 3.087\n",
      "Epoch: 066 | MSE: 3.087\n",
      "Epoch: 067 | MSE: 3.087\n",
      "Epoch: 068 | MSE: 3.087\n",
      "Epoch: 069 | MSE: 3.087\n",
      "Epoch: 070 | MSE: 3.087\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "linreg = LinearRegression(num_features=X_train.size(1))\n",
    "linreg.to(device)\n",
    "linreg.train(X_train, y_train, num_epochs=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed856fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEFCAYAAADuT+DpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcyElEQVR4nO3de5hcdZ3n8fepqr5Vd6XTSYqEQALD7bvgcncBQSDOA3LRER92GMfrqLuOs8OsuOszuCruyKjjuuuw42VUFi/oqMsoCMvwLAvrBQwMLiIgRPEbrnIL0Em6k046fa3aP05VU2m6092VPqeq+vd5PQ+k6lTl1CcN6U//fuec34nK5TIiIhKuTKMDiIhIY6kIREQCpyIQEQmcikBEJHAqAhGRwOUaHaAe/f1DdZ/q1NeXZ2BgeDHjJEp5k9dqmZU3WUs5b7FYiGbaHtyIIJfLNjrCgihv8lots/ImK8S8wRWBiIjsTUUgIhI4FYGISOBUBCIigVMRiIgETkUgIhK4RIvAzE41szumbXubmd1T8/x9Znafmf3czN6YZB4REXmlxIrAzC4HvgZ01mw7Efg3QFR5vgb4AHAGcB7wGTPrSCqTPz3ATXc+ntTuRURaUpIjgseBi6tPzGwl8DfAB2vecwpwt7uPuvsO4DHguKQC/d/7nuXrN29ieGQiqY8QEWk5iS0x4e43mNmhAGaWBb4O/EdgT83blgE7ap4PAb1z7buvL1/X1XTLCvFgo6u7g+KK/IJ/f6MUi4VGR1iQVssLrZdZeZMVWt601ho6GTgS+ArxVNExZvZ3wE+A2j9BARica2f1rgOSraxQ9Mzzg0STk3XtI23FYoH+/qFGx5i3VssLrZdZeZO1lPPOVhipFIG73wu8CqAySrjO3T9YOUbwaTPrBDqAo4FNSeXo6oz/uHtGNTUkIlLV0NNH3f0F4AvARuLRwcfcfSSpz8t3xEUwrCIQEZmS6IjA3Z8CTtvXNne/BrgmyRxV+cqIQAeLRUReFtQFZRoRiIi8UlBFMHWMQCMCEZEpQRWBRgQiIq+kIhARCVxQRaCpIRGRVwqqCDQiEBF5paCKIJfN0N6WVRGIiNQIqggAerpymhoSEakRXBF0d7VpRCAiUiO8IuhsY3hkgnK53OgoIiJNIbgiyHe1USqXGRsvNTqKiEhTCK4IejrbAJ05JCJSFVwRdHdVimBkvMFJRESaQ7hFoBGBiAgQYBHkdXMaEZG9BFcEPVNTQyoCEREIsAg0NSQisrdgi0BTQyIisfCKoFNTQyIitcIrAk0NiYjsJdwi0IhARASAXJI7N7NTgc+6+wYzOwH4IjAJjALvcvcXzex9wPuBCeBT7n5Lkpl0jEBEZG+JjQjM7HLga0BnZdPngX/v7huAHwIfNrM1wAeAM4DzgM+YWUdSmQDacxmymUhTQyIiFUlODT0OXFzz/I/d/cHK4xwwApwC3O3uo+6+A3gMOC7BTERRRL4zp6khEZGKxKaG3P0GMzu05vkWADM7HfgL4CziUcCOmt82BPTOte++vjy5XLbubIV8O8OjExSLhbr3kaZWyVnVanmh9TIrb7JCy5voMYLpzOwtwMeAN7h7v5ntBGr/BAVgcK79DAwM152hWCzQ0Zahf3Cc/v6huveTlmKx0BI5q1otL7ReZuVN1lLOO1thpFYEZvYO4oPCG9x9e2XzvcCnzawT6ACOBjYlnaWrI8f4RInxiUna9mNkISKyFKRSBGaWBb4APA380MwA7nT3vzKzLwAbiY9XfMzdR5LOk++I/9jDo5P0qghEJHCJFoG7PwWcVnm6Ypb3XANck2SO6aorkA6PjNPb3Z7mR4uINJ3gLigDyHdUryWYbHASEZHGC7IIujri6aDhUd2lTEQkyCLIa+E5EZEpYRbB1MFiFYGISJBF0KXbVYqITAmyCKZGBJoaEhEJvAg0IhARCbQINDUkIjIlyCLo0tSQiMiUIIugsz1LFGlqSEQEAi2CKIrId+TYoxGBiEiYRQDx9JBGBCIiARdBvlNFICICIRdBR47RsUkmS6VGRxERaahgi6B65pBWIBWR0AVbBFP3JND0kIgELtwiqN6TQGcOiUjggi2CqXsSjOieBCIStmCLYOqeBJoaEpHAhVsEWnhORAQIuAimzhrSMQIRCVwuyZ2b2anAZ919g5kdAVwLlIFNwKXuXjKzvwLeAEwAH3T3e5PMVKWzhkREYomNCMzscuBrQGdl01XAFe5+JhABF5nZScDZwKnAHwN/n1Se6XRzGhGRWJIjgseBi4F/qDw/Gbiz8vhW4PWAA7e7exl42sxyZlZ09/597bivL08ul607WLFYYDITd2ApiigWC3XvKw3Nnm+6VssLrZdZeZMVWt7EisDdbzCzQ2s2RZVv+ABDQC+wDNhW857q9n0WwcDAcN25isUC/f1D7NkTnzY6sGMP/f1Dde8vadW8raLV8kLrZVbeZC3lvLMVRpoHi2sX9SkAg8DOyuPp2xP38nUEmhoSkbClWQQPmNmGyuMLgI3A3cB5ZpYxs/VAxt23phEmm8nQ2Z7V7SpFJHiJnjU0zYeAa8ysHXgEuN7dJ81sI3APcSldmmIeLUUtIkLCReDuTwGnVR5vJj5DaPp7PgF8Iskcs+nqyDGwc7QRHy0i0jSCvaAM4lNI94xOUCqX536ziMgSFXwRlIHRMd2TQETCFXYRdOqiMhGRoIugSwvPiYiEXQQvjwh0TwIRCVfYRVC9S5nuWywiAQu7CKZWINWIQETCFXQRVI8R7NbBYhEJWNBF0NMVTw3tGtaIQETCFXQRLO9pB2DHbl1dLCLhCroIervjIhjcNdbgJCIijRN0EXR15GjLZdixW0UgIuEKugiiKKK3u50duzQ1JCLhCroIAJb3dLBz9zilkhaeE5EwBV8EvT3tlMplhvbozCERCZOKoHLAWNNDIhIqFUFPB4AOGItIsIIvguVTp5BqRCAiYQq+CKZGBLqWQEQCFXwRTF1drCIQkUAFXwRTVxdrmQkRCVQuzQ8zszbgW8ChwCTwPmACuBYoA5uAS929lFamQr6dKNLBYhEJV9ojgguBnLufDvw18GngKuAKdz8TiICL0gyUyUQs09XFIhKwVEcEwGYgZ2YZYBkwDpwG3Fl5/Vbg9cCN+9pJX1+eXC5bd4hisbDX81XLu3jmxV2sWtVDFEV17zcp0/M2u1bLC62XWXmTFVretItgF/G00G+BVcAbgbPcvbq+wxDQO9dOBgaG6w5QLBbo7x/aa1t3R46x8UmefnZw6q5lzWKmvM2s1fJC62VW3mQt5byzFUbaU0P/AbjN3Y8Cjic+XtBe83oBGEw508tXF+uAsYgEaJ9FYGYH7eO136/j8waAHZXH24E24AEz21DZdgGwsY797hddSyAiIZtrRPBP1QdmdsO01z5Xx+f9d+AkM9sI/AT4KHApcKWZ3UM8Ori+jv3ul+q1BDqFVERCNNeEeO2R08P28dq8uPsu4I9meOnshe5rMfV2a0QgIuGaa0RQnuXxTM9bVq+uLhaRgAV/ZTHULDynqSERCdBcU0MHmtl/nuFxBKxJLla6NCIQkZDNVQRf5eVjAbWPAa5OJFEDtOWydHfmtMyEiARpn0Xg7lemFaTRens6tMyEiARpn0VgZl3AJ4Hvu/u9ZnYV8UJxDwBvdffnUsiYit7udp7fupvxiUna9mP5ChGRVjPXweLPA3ngKTO7EHg7cCLxQnFfSjhbqnScQERCNVcRvMbd/9zdXyJeFfT77v6Yu98EWOLpUrS8W/cuFpEwzVUEkzWPNwA/qnnezhJSHREMakQgIoGZ66yhbWZ2CtADHESlCCprAz2bbLR0TU0N6VoCEQnMXEXwQeAfgdXAn7v7bjO7AvgA8IaEs6WqusyERgQiEpq5iuBE4L9QuX7AzN4FbCG+s9jRwC8STZei6sJzOzUiEJHAzFUE1wIvEU8JjbH3BWVl4NvJxEqfRgQiEqq5iuAk4C3AucCvgOuAH6V5c/m0dHVkac9ldPqoiARnriuLHwQeBD5iZq8mLoW/MbP7gOvc/Y6kA6YliiJ6e9q18JyIBGfeq4+6+33u/pfEt5s8FrglsVQN0tvdwc7dY5RKS2aFbRGROc15p3Yzi4CzgEuIbyX5IPBFau5etlT09rRTLsPQnvGp+xiLiCx1c6019BXgfOK1hb4PfNjdd6cRrBGmri7eNaoiEJFgzDUieD+wjfg00hOJjw9Mveju029f2dJqry5ev7rBYUREUjJXEfxeKimaxMsLz+mAsYiEY66zhn632B9oZh8B3kS8VtGXgTuJr1coA5uASxt1eurUtQRaeE5EApLqPYsraxSdDpwBnA2sI17S+gp3P5P4grWL0sxUa+rqYl1LICIBSfvm9ecBDwM3Ep91dAtwMvGoAOBW4JyUM03p7amOCDQ1JCLhmPP00UW2CjgEeCPx8YebgYy7V0/cHwJ659pJX1+e3H7cRaxYLMy4feXKMplMxPDo5KzvaYRmyjIfrZYXWi+z8iYrtLxpF8E24LfuPga4mY0QTw9VFYDBuXYyMDBcd4BisUB//9Csr/d2t/PS9t37fE+a5srbbFotL7ReZuVN1lLOO1thpD01dBdwvplFZrYW6AZ+XDl2APEFaxtTzrSXA5Z3sX3nKGPjk3O/WURkCUi1CNz9FuKL0+4lPkZwKfAh4Eozu4f4TKLr08w03ZqVecrASwN7GhlDRCQ1aU8N4e6Xz7D57LRzzGbNijwAL2wf5uADehqcRkQkeWlPDTW9ahFs2V7/cQgRkVaiIphmzcrKiGCbikBEwqAimGZVbyfZTMQLGhGISCBUBNNkMxkO6Ovihe3DlMu6L4GILH0qghmsWZFnz+gEO4fHGx1FRCRxKoIZvHycYMneekFEZIqKYAa1p5CKiCx1KoIZHLiiG1ARiEgYVAQz0CmkIhISFcEMerra6Olq04hARIKgIpjFmhV5+gdHmJhsyM3SRERSoyKYxZoVeUrlMv2DWnxORJY2FcEsdJxAREKhIpiFTiEVkVCoCGahVUhFJBQqglkc0NdFJtLicyKy9KkIZpHLZli1vFPHCERkyVMR7MOaFXl27Rln1x4tPiciS5eKYB90wFhEQqAi2AedQioiIVAR7MOBGhGISAByjfhQMzsA+CVwLjABXAuUgU3Ape7eFOs6aGpIREKQ+ojAzNqAq4Hq2g1XAVe4+5lABFyUdqbZLOtup6sjqyIQkSWtEVNDnwO+CjxfeX4ycGfl8a3AOQ3INKMoilizIs9LA8OUSrp/sYgsTalODZnZu4F+d7/NzD5S2Ry5e/W77BDQO9d++vry5HLZunMUi4V5v/eQtb08uWWIUjbL6lXddX/m/lhI3mbQanmh9TIrb7JCy5v2MYL3AmUzOwc4Afg2cEDN6wVgcK6dDAzUP1VTLBbo7x+a9/v7utsBeNhfJFcu1v259Vpo3kZrtbzQepmVN1lLOe9shZHq1JC7n+XuZ7v7BuBB4F3ArWa2ofKWC4CNaWaay+FrlwHw6LM7GpxERCQZDTlraJoPAdeYWTvwCHB9g/Ps5fC1vWQzEZufHWx0FBGRRDSsCCqjgqqzG5VjLh3tWdavLvC7F4YYHZuko73+YxMiIs1IF5TNg61bzmSpzBPPa3pIRJYeFcE8HLkuPpFps44TiMgSpCKYhyMPXg7A5mcGG5pDRCQJKoJ56Olq46BV3Tz+/A4mJpti9QsRkUWjIpinI9ctZ2y8xO9ebJ3zi0VE5kNFME9HHRwfJ3j0GR0nEJGlRUUwT0etWw7oOIGILD0qgnlasayTVb2dPPrsIKWyFqATkaVDRbAARx68nN0jE2zZurvRUUREFo2KYAGOql5PoOkhEVlCVAQLMHWcQBeWicgSoiJYgDUr8hTybWx+ZpCyjhOIyBKhIliAKIo48uDlDAyNsm3HSKPjiIgsChXBAlWvJ9Cy1CKyVKgIFujIynECf3qwoTlERBaLimCB1q/uYVl3O/dv7md8QusOiUjrUxEsUDaT4bRjVrN7ZIJfPba10XFERPabiqAOZxx7IAD/vOmFBicREdl/KoI6rDugh0NWF3jo8W3s2D3W6DgiIvtFRVCnM45dQ6lc5ue/1qhARFqbiqBOpx6zmmwm4u6Ht+jiMhFpabk0P8zM2oBvAIcCHcCngN8A1wJlYBNwqbs3/ek4hXw7xx+xivs39/P0i7s4ZE2h0ZFEROqS9ojgHcA2dz8TOB/4EnAVcEVlWwRclHKmup1x7BoA7n54S4OTiIjUL+0i+AHw8crjCJgATgburGy7FTgn5Ux1O/awlRTybfz8Ny/qXsYi0rJSnRpy910AZlYArgeuAD7n7tVJ9iGgd6799PXlyeWydecoFhdvGud1r17HzT97gqf6h3lN5bTSxbaYedPQanmh9TIrb7JCy5tqEQCY2TrgRuDL7v49M/uvNS8XgMG59jEwMFz35xeLBfr7F+8G9CcdvpKbf/YEt979BEes6Vm0/VYtdt6ktVpeaL3MypuspZx3tsJIdWrIzFYDtwMfdvdvVDY/YGYbKo8vADammWl/rV9dYP0BPTz0+Da2Du5pdBwRkQVL+xjBR4E+4ONmdoeZ3UE8PXSlmd0DtBNPGbWU805dz2SpzPd/+lijo4iILFjaxwguAy6b4aWz08yx2E47ZjU/vf857vN+HnlqO0cfuqLRkURE5k0XlC2CKIp427lHEgHf+9GjTJZ0BpGItA4VwSI5dM0yzjx+Lc9t3c1P73+u0XFEROZNRbCILj77MLo6cty08UmGhrUYnYi0BhXBIlqWb+fNr/09hkcnuPFnTzQ6jojIvKgIFtnrTjqItau6ufPB53nqhZ2NjiMiMicVwSLLZTO89ZwjKQNfvOFhtu8caXQkEZF9UhEk4FWHruCSDYczMDTK3/7jg+zaM97oSCIis1IRJOT8U9dz3inr2LJtmL/7wa8YGZtodCQRkRmpCBISRRGXvO4IXvOqNTzx/E6+fOMmrVAqIk1JRZCgTBTxngv/BccdvpJNT27n6pt/zZ5RjQxEpLmoCBKWy2b4d2/+lxx5cC+/9H4+8c17eey5HY2OJSIyRUWQgo62LH/51hO58LRD2Do4wme+80tu2viEpopEpCmoCFKSy2b4ww2Hc/nbTmRFoYOb736Kz3znfvzpAcrl8tw7EBFJiIogZba+jyvfewqnHbOaJ7fs5LPfe4BPfus+7n3kRS1WJyINkfodygTynW386Ztexe+fdDC33fs092/u56v/69esXNbJmccdyHFHrGT96gKZKGp0VBEJgIqggY44uJcjDj6WFweGuf0Xz3D3Q1u46a4nuemuJ+ntbufYw1dy+vEHsSKfo7i8i0jFICIJUBE0gdV9ed75euNfn3UYm57czkOPb+PhJ7Zx10NbuOuhLQB0dWRZV+xh3eoCq/u6WNnbyareLlYu6yTfqf+MIlI/fQdpIvnONk45ejWnHL2aUrnMU1uGeGbbML99chtPvzjEo8/uYPOzrzz1tKMtSyHfRk9XG4V8Oz1dOTo7cnS15+hsz9LZnqWjLUtbLkNbrvprhlw2Ipup/JrNkM1EZDIR2Sj+NZOJyETxxXGZKCKK4msjiJjaDhBvirfrwLdI61ERNKlMFHHY2mWcevxB9PevAWB0bJLntu5m6449bN0xwrYdI2zbOcLg0ChDe8Z5tn83E5NDDU6+t2jqX9XnL5fHXu+bcdYrmsd79vU75imKoFEFVkfgKIpaqnCVd/F0tGW57A+P57C1yxZ1vyqCFtLRnuWwtctm/Z+gXC4zNl5iaM8YI6OTjIxNMjI2wcjYJKPjk4xPlBifKDE2ET+eLJWZnCwzMVliolSmVCpRKsFkqUypXGayVKZcLlMqlSmXoVT5y1Eql6HyvPr3pfoXJ9eWZWxssrqR2r9O5WkPyi8/eOWf5RV/tvl8her7y5vLZZmYmKzr9+6Per/X5NqyTIynn7deyrt4OtqyiUwFqwiWkCiK6GjP0tHe1bAMxWKB/v7mGpXMpdUyK2+yWi3vYmiKIjCzDPBl4HhgFPi37v5YY1OJiIShWS4oezPQ6e6vAf4T8LeNjSMiEo6oGQ6KmNlVwL3ufl3l+XPuftBs75+YmCznctnU8omILBEznp7QFFNDwDKg9rzISTPLufuMazYPDAzX/UGtNv+nvMlrtczKm6ylnLdYLMy4vVmmhnYCtQkzs5WAiIgsrmYpgruBCwHM7DTg4cbGEREJR7NMDd0InGtm/0w8h/WeBucREQlGUxSBu5eAP2t0DhGREDXFWUMiItI4zXKMQEREGkRFICISOBWBiEjgVAQiIoFTEYiIBE5FICISOBWBiEjgmuKCsjS00j0PzOxU4LPuvsHMjgCuJb791ibg0soFeA1nZm3AN4BDgQ7gU8BvaN68WeAawIjz/RkwQpPmrTKzA4BfAucCEzR/3vuJ1w8DeBK4Gvg8cfbb3f3KRmWbiZl9BHgT0E78PeJOmvRrbGbvBt5dedoJnABsYD+/viGNCN5MC9zzwMwuB75G/B8Z4CrgCnc/k3j5jYsalW0G7wC2VbKdD3yJ5s77BwDufgZwBfBpmjtvtWyvBvZUNjV73k4gcvcNlX/eA3wVeBvwWuBUMzuxoSFrmNkG4HTgDOBsYB1N/DV292urX1viHw4+wCJ8fUMqgtcC/wfA3X8OvLqxcWb1OHBxzfOTiX9CAbgVOCf1RLP7AfDxyuOI+CeSps3r7jcBf1p5eggwSBPnrfgc8V/05yvPmz3v8UDezG43s5+Y2VlAh7s/7u5l4DaaK/N5xItc3gj8E3ALzf81xsxeDbwKuI5F+PqGVAQz3vOgUWFm4+43AOM1m6LKf2CAIaA3/VQzc/dd7j5kZgXgeuKfsps2L4C7T5jZt4AvAt+lifNWpgH63f22ms1Nm7dimLi8ziOeevtmZVtVs2VeRfxD4SXEeb9LvAx+M3+NAT4KXEn8fW1nzfa68oZUBK16z4PauckC8U+xTcPM1gE/Bf7B3b9Hk+cFcPc/AY4iPl7QVfNSs+V9L/GqvHcQzwV/Gzig5vVmywuwGfiOu5fdfTPxD18ral5vtszbgNvcfczdnfiYUe030mbLi5ktB8zdf8orv6/VlTekImjVex48UJnHBLgA2NjALHsxs9XA7cCH3f0blc3NnPedlQODEP+UWgLua9a87n6Wu59dmQ9+EHgXcGuz5q14L5Xjb2a2FsgDu83scDOLiEcKzZT5LuB8M4sqebuBHzf51/gs4McA7r4TGNvfr2/TTY0kqFXvefAh4BozawceIZ6CaRYfBfqAj5tZ9VjBZcAXmjTvD4FvmtnPgDbgg8QZm/XrO5Nm/v8B4OvAtWZ2F/FZN+8lLtzvAlnis1r+XwPz7cXdb6kcx7iX+AfjS4nPdGrmr7EBT9Q8r05p1f311TLUIiKBC2lqSEREZqAiEBEJnIpARCRwKgIRkcCpCEREAhfS6aMi82ZmhxJfHPWbaS9d4+5/vwj73wB8onKNgEhDqQhEZve8u5/Q6BAiSVMRiCyQmfXz8uJkQ8Db3f2pyhXrnydeOXYr8H53f8zMTiBeQTQPbAfeXtlV0cz+N3A44MAl7j6a6h9GBB0jENmXtWb24LR/jiVeqOwOdz+OePXH6pXU1wF/4e7HE68Y+j8r+/ku8El3P7bynssq29cTX8l6NLCGJlzlUsKgEYHI7GacGjKzEeIF4AC+BXyGeBG7AXf/BYC7/8DM/oeZHQIc6O63VLZ/pbKPDcCv3P3JyvNHiAtGJHUqApGFK9UsU5whvg/DTKPraPqGyo1b1lae1q5+W57p/SJp0NSQyMLlzewPKo/fQ3zzEgdWmtm/AjCzPwJ+5+6/A54xs3Mr738n8NdpBxbZF40IRGa31swenLbtZ5VfLzGzTxPfOexP3H3UzN4CfMnMuokPCr+l8t53AF8xs/9GfBD5ncQrSIo0Ba0+KrJAZlZ2d03jyJKhqSERkcBpRCAiEjiNCEREAqciEBEJnIpARCRwKgIRkcCpCEREAvf/Af+yasuPXkOQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the MSE-loss after each epoch\n",
    "plt.plot(range(len(cost)), cost)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee37a0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [('TV', tensor([4.0620, 0.0737, 2.7096]))]\n",
      "Intercept: tensor([13.8107])\n",
      "- MSE: 2.872\n"
     ]
    }
   ],
   "source": [
    "# examine the coefficients and intercept\n",
    "print(f'Coefficients: {list(zip(feature_cols, linreg.linear.weight.detach()))}')\n",
    "print(f'Intercept: {linreg.linear.bias.detach()}')\n",
    "print(f'- MSE: {F.mse_loss(y_test, linreg.predict(X_test).detach()):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ec660",
   "metadata": {},
   "source": [
    "**Use scikit-learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96ab6faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [('TV', 4.0620537), ('Newspaper', 0.073443495), ('Radio', 2.7098477)]\n",
      "Intercept: 13.8107\n",
      "- MSE: 2.872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "print(f'Coefficients: {list(zip(feature_cols, linreg.coef_))}')\n",
    "print(f'Intercept: {linreg.intercept_:.4f}')\n",
    "print(f'- MSE: {mean_squared_error(y_test, y_pred):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f297c3",
   "metadata": {},
   "source": [
    "**Analytical solution**\n",
    "$$(X^T.X)^{-1}.X^T.y$$\n",
    "- Set: $$a = (X^T.X)^{-1}, b=a.X^T, w=b.y$$\n",
    "- After finding w, we can compute the bias by: \n",
    "$$bias = W.X - y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16595779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [('TV', 4.062052), ('Newspaper', 0.07344389), ('Radio', 2.7098463)]\n",
      "Intercept: 15.089\n"
     ]
    }
   ],
   "source": [
    "a = torch.inverse(torch.mm(X_train.T, X_train))\n",
    "b = torch.mm(a, X_train.T)\n",
    "\n",
    "w = torch.mm(b, y_train.view(-1, 1))\n",
    "bias = (y_train - torch.mm(X_train, w).view(-1))[0]\n",
    "\n",
    "print(f'Coefficients: {list(zip(feature_cols, w.view(-1).numpy()))}')\n",
    "print(f'Intercept: {bias:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
